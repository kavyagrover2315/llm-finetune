def complete_code(prompt):
    model.eval()
    input_text = f"<|user|>\n{prompt}\n<|assistant|>\n"
    inputs = tokenizer(input_text, return_tensors="pt").to(model.device)
    with torch.no_grad():
        output = model.generate(
            **inputs,
            max_new_tokens=150,
            do_sample=True,
            top_p=0.95,
            temperature=0.7,
            pad_token_id=tokenizer.eos_token_id
        )
    result = tokenizer.decode(output[0], skip_special_tokens=True)
    return result.split("<|assistant|>")[-1].strip()

print(complete_code("Write a Python class for a calculator."))
